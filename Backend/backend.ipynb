{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3affd234-7c0c-46a7-9717-5342c797c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import dask.dataframe as dd\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Set up AWS S3 connection\n",
    "fs = s3fs.S3FileSystem()\n",
    "bucket_name = '608project'\n",
    "\n",
    "borough_mapping = {\n",
    "    'MANHATTAN': 'M',\n",
    "    'BRONX': 'B',\n",
    "    'BROOKLYN': 'K',\n",
    "    'STATEN ISLAND': 'S',\n",
    "    'QUEENS': 'Q'\n",
    "}\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=8)\n",
    "\n",
    "def load_data(year):\n",
    "    file_path = f's3://{bucket_name}/nypd_cleaned_{year}.parquet'\n",
    "    try:\n",
    "        data = dd.read_parquet(file_path, filesystem=fs)\n",
    "        print(f\"Loaded data for year {year}, columns: {data.columns}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for year {year}: {e}\")\n",
    "        return dd.from_pandas(pd.DataFrame(), npartitions=1)  # Return an empty dataframe if an error occurs\n",
    "\n",
    "def filter_data(data, boroughs, offenses, ethnicities, genders, age_categories):\n",
    "    try:\n",
    "        filtered = data[\n",
    "            (data['ARREST_BORO'].isin(boroughs)) &\n",
    "            (data['OFNS_DESC'].isin(offenses)) &\n",
    "            (data['PERP_RACE'].isin(ethnicities)) &\n",
    "            (data['PERP_SEX'].isin(genders)) &\n",
    "            (data['AGE_GROUP'].isin(age_categories))\n",
    "        ]\n",
    "        return filtered\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError during filtering: {e}\")\n",
    "        raise\n",
    "\n",
    "@app.route('/filter', methods=['POST'])\n",
    "def filter_data_endpoint():\n",
    "    req = request.json\n",
    "    years = req.get('years', [])\n",
    "    boroughs = req.get('boroughs', [])\n",
    "    offenses = req.get('offenses', [])\n",
    "    ethnicities = req.get('ethnicities', [])\n",
    "    genders = req.get('genders', [])\n",
    "    age_categories = req.get('age_categories', [])\n",
    "\n",
    "    # convert borough names to codes\n",
    "    borough_codes = [borough_mapping.get(borough, borough) for borough in boroughs]\n",
    "\n",
    "    # Will load data for the specified years in parallel\n",
    "    futures = [executor.submit(load_data, year) for year in years]\n",
    "    data_frames = [future.result() for future in as_completed(futures)]\n",
    "    data = dd.concat(data_frames)\n",
    "\n",
    "\n",
    "    try:\n",
    "        filtered_data = filter_data(data, borough_codes, offenses, ethnicities, genders, age_categories).compute()\n",
    "        return jsonify(filtered_data[['ARREST_DATE','ARREST_BORO', 'OFNS_DESC', 'PERP_RACE', 'PERP_SEX', 'AGE_GROUP', 'Latitude', 'Longitude']].to_dict(orient='records'))\n",
    "    except Exception as e:\n",
    "        print(f\"Error during filtering: {e}\")\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/getdata', methods=['GET'])\n",
    "def get_data():\n",
    "    year = request.args.get('year')\n",
    "    \n",
    "    if not year:\n",
    "        return jsonify({'error': 'Year parameter is required'}), 400\n",
    "\n",
    "    try:\n",
    "        data = load_data(year).compute()\n",
    "        return jsonify(data[['ARREST_DATE','ARREST_BORO', 'OFNS_DESC', 'PERP_RACE', 'PERP_SEX', 'AGE_GROUP', 'Latitude', 'Longitude']].to_dict(orient='records'))\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for year {year}: {e}\")\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/data-summary', methods=['GET'])\n",
    "def data_summary():\n",
    "    year = request.args.get('year')\n",
    "    if not year:\n",
    "        return jsonify({'error': 'Year parameter is required'}), 400\n",
    "\n",
    "    try:\n",
    "        data = load_data(year).compute()\n",
    "        summary = {\n",
    "            'total_records': len(data),\n",
    "            'boroughs': data['ARREST_BORO'].unique().tolist(),\n",
    "            'offenses': data['OFNS_DESC'].unique().tolist(),\n",
    "            'ethnicities': data['PERP_RACE'].unique().tolist(),\n",
    "            'genders': data['PERP_SEX'].unique().tolist(),\n",
    "            'age_categories': data['AGE_GROUP'].unique().tolist()\n",
    "        }\n",
    "        return jsonify(summary)\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing data for year {year}: {e}\")\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
